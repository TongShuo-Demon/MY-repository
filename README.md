# MY-repository

2019/10/08
今天结合之前代码看了opencv--SVM部分知识，晚上看了cmake部分知识（https://www.cnblogs.com/52php/p/5681755.html）

2019/10/9------2019/10/15
完成一个小项目，实现练手的目的，识别身份证号码区域，并截取号码图片，使用SVM识别数字并显示出来


2019/10/15------2019/10/17
完成对Ubuntu系统重新安装，解决了home空间不够用的问题，包含大华相机驱动问题、opencv和扩展库，tensorflow,eigen等

2019/10/18------2019/10/24
仿照上交代码实现读取识别，圈出候选装甲板区域。


2019/10/25------2019/10/25
读和看去年的代码，使用简单的训练集训练出来的模型，对装甲板候选区域图片进行识别。


2019/10/26
学会对大华相机的使用，将去年的相机驱动移植到，自己的工程文件，经测试可以使用。


2019/10/27
将大华相机与之前做的自瞄结合在一起使用，实现识别作用，
效果：1，可以圈出正面装甲板，但是当出现倾斜界面时候，无法圈出装甲板
     2，利用之前识别身份证数字训练出来的模型，无法准确识别出装甲板数字
     
待做：重新制作训练集来提高准确率

2019/10/28
1，采集了6000张图片，采集的图片圈出了两个灯条，0、1、2、3、4、5六个数字，每个数字包含了1000张图片
2，效果：（1） 经测试，效果依然不是很理想，但是相比较27号的准确率得到了一定的提高。
        （2）对于倾斜的图片依然识别不出
3，看了去年的代码，发现存在将图片矫正的代码，可以采用此方法。
待做：在看去年代码和上交的开源代码，进行对比。


2019/10/29
1，对比了去年的代码和上交的代码，发现去年的命名空间部分写的很好，可以直接通过xml文件将需要经常改的参数进行修改，比较直接快速。
   于是自己将仿照此方法写了代码。
2，发现上交的代码写了很多小函数，可观性比较强
3，晚上看了已经注释的去年代码，对于 灯条内部目标颜色百分比 部分存在疑问，有待深入理解，测试这段代码发现加和不加区别很大。
4，自己重写代码时候，发现point2f不能进行赋值，留待明天解决。

2019/10/30（准备数学方法考试）
1,对于前一天的point2f问题，发现去年航哥进行赋值是为了方便计算装甲板的四个坐标点，而我是用定义灯条类和装甲板类，不需要进行这步操作。
2，完成匹配灯条类的筛选工作的代码部分。

2019/10/31（准备数学方法考试）
1，看了透射变换的原理，学习了API接口函数（warpPerspective，getPerspectiveTransform）






